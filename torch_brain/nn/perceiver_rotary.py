from typing import Dict, List, Optional, Tuple, Union

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchtyping import TensorType

from torch_brain.nn import RotaryEmbedding, RotaryCrossAttention, RotarySelfAttention


class GEGLU(nn.Module):
    def forward(self, x):
        x, gates = x.chunk(2, dim=-1)
        return x * F.gelu(gates)


class FeedForward(nn.Module):
    def __init__(self, dim, mult=4, dropout=0.2):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(dim, dim * mult * 2),
            GEGLU(),
            nn.Dropout(p=dropout),
            nn.Linear(dim * mult, dim),
        )

    def forward(self, x):
        return self.net(x)
    

"""
Assumes that input is tensor of shape (B, N, D) where B is the batch size, N is the number of samples, and D is the dimensionality of the samples.
It's also assumed that N was computed as N=T*K, where T is the number of unique timestamps and K is the number of token indexes per timestamp (e.g.
units/channels, latents, sessions). We'd like to determine the coefficient of variation across timestamps, since we're observing constant 
output wrt time. Hence we expect the CV to decrease close to 0 as the signal propagates through the network.

Note: sampling_rate is the number of timestamps per sample (K of them).
"""
def coef_variation(x, sampling_rate):
    if x is None:
        return 0.0
    
    # First reshape the tensor to (B, T, K, D)
    B, _, D = x.shape
    x = x.view(B, sampling_rate, -1, D)

    # Compute the mean and standard deviation across the timestamps
    mean = x.mean(dim=1)
    std = x.std(dim=1)
    cv = std / torch.abs(mean)

    # Compute the mean CV across indexes and the batch
    cv = cv.mean(dim=-1).mean()
    return cv


class PerceiverRotary(nn.Module):
    def __init__(
        self,
        *,
        dim=512,
        context_dim=None,
        dim_head=64,
        depth=2,
        cross_heads=1,
        self_heads=8,
        ffn_dropout=0.2,
        lin_dropout=0.4,
        atn_dropout=0.0,
        batch_type: Union[str, Tuple[str, str, str]] = "stacked",
        backend: Union[str, Tuple[str, str, str]] = "math",
        t_min=1e-4,
        t_max=4.0,
    ):
        super().__init__()

        if isinstance(batch_type, str):
            batch_type = (batch_type, batch_type, batch_type)
        assert len(batch_type) == 3
        self.batch_type = batch_type

        if isinstance(backend, str):
            backend = (backend, backend, backend)
        assert len(backend) == 3
        self.backend = backend

        self.rotary_emb = RotaryEmbedding(dim_head, t_min, t_max)

        self.dropout = nn.Dropout(p=lin_dropout)

        # Encoding transformer (q-latent, kv-input spikes)
        self.enc_atn = RotaryCrossAttention(
            dim=dim,
            context_dim=context_dim,
            heads=cross_heads,
            dropout=atn_dropout,
            dim_head=dim_head,
            rotate_value=True,
            batch_type=batch_type[0],
            backend=backend[0],
        )
        self.enc_ffn = nn.Sequential(
            nn.LayerNorm(dim), FeedForward(dim=dim, dropout=ffn_dropout)
        )

        # Processing transfomers (qkv-latent)
        self.proc_layers = nn.ModuleList([])
        for i in range(depth):
            self.proc_layers.append(
                nn.ModuleList(
                    [
                        RotarySelfAttention(
                            dim=dim,
                            heads=self_heads,
                            dropout=atn_dropout,
                            dim_head=dim_head,
                            rotate_value=True,
                            batch_type=batch_type[1],
                            backend=backend[1],
                        ),
                        nn.Sequential(
                            nn.LayerNorm(dim),
                            FeedForward(dim=dim, dropout=ffn_dropout),
                        ),
                    ]
                )
            )

        self.dec_atn = RotaryCrossAttention(
            dim=dim,
            heads=cross_heads,
            dropout=atn_dropout,
            dim_head=dim_head,
            rotate_value=False,
            batch_type=batch_type[2],
            backend=backend[2],
        )
        self.dec_ffn = nn.Sequential(
            nn.LayerNorm(dim), FeedForward(dim=dim, dropout=ffn_dropout)
        )

        self.dim = dim

    def forward(
        self,
        *,  # (   stacked  ) or (   chained   )
        inputs,  # (B, N_in, dim) or (N_all_in, dim)
        latents,  # (B, N_latent, dim) or (N_all_latent, dim)
        output_queries,  # (B, N_out, dim) or (N_all_out, dim)
        input_timestamps,  # (B, N_in) or (N_all_in,)
        latent_timestamps,  # (B, N_latent) or (N_all_latent,)
        output_query_timestamps,  # (B, N_out) or (N_all_out,)
        input_mask=None,  # (B, N_in) or None
        input_seqlen=None,  # None or (B,)
        latent_mask=None,  # (B, N_latent) or None
        latent_seqlen=None,  # None or (B,)
        output_query_seqlen=None,  # None or (B,)
    ) -> Union[
        TensorType["batch", "*nqueries", "dim"],  # if padded
        TensorType["ntotal_queries", "dim"],  # if chained
    ]:
        if latent_mask is not None:
            raise NotImplementedError("latent_mask is not supported yet.")
        
        # print(f"Inputs CV (1): {coef_variation(inputs, 100)}")
        # print(f"Latents CV (1): {coef_variation(latents, 30)}")
        # print(f"Output Queries CV (1): {coef_variation(output_queries, 30)}")

        # compute timestamp embeddings
        input_timestamp_emb = self.rotary_emb(input_timestamps)
        latent_timestamp_emb = self.rotary_emb(latent_timestamps)

        # make sure arguments make sense
        if self.batch_type[0] == "stacked":
            assert inputs.dim() == 3, (
                f"Expected stacked inputs with 3 dimensions (batch, num_tokens, dim), "
                f"got ({inputs.shape})."
            )
            assert latents.dim() == 3, (
                f"Expected stacked latents with 3 dimensions (batch, num_tokens, dim), "
                f"got ({latents.shape})."
            )
            # assert (
            #     input_seqlen is None
            # ), f"input_seqlen should be None as it will not be used."
        elif self.batch_type[0] == "chained":
            assert inputs.dim() == 2, (
                f"Expected chained inputs with 2 dimensions (num_tokens, dim), "
                f"got ({inputs.shape})."
            )
            assert latents.dim() == 2, (
                f"Expected chained latents with 2 dimensions (num_tokens, dim), "
                f"got ({latents.shape})."
            )
            assert (
                input_mask is None
            ), f"input_mask should be None as it will not be used."
            assert input_seqlen is not None, f"input_seqlen should be provided."
            assert latent_seqlen is not None, f"latent_seqlen should be provided."

        # encode
        latents = latents + self.enc_atn(
            latents,
            inputs,
            latent_timestamp_emb,
            input_timestamp_emb,
            context_mask=input_mask,  # used if default attention
            query_seqlen=latent_seqlen,  # used if memory efficient attention
            context_seqlen=input_seqlen,  # used if memory efficient attention
        )
        # print(f"Latents CV (2): {coef_variation(latents, 30)}")
        latents = latents + self.enc_ffn(latents)
        # print(f"Latents CV (3): {coef_variation(latents, 30)}")

        # reshape latents if needed
        if self.batch_type[0] == "stacked" and self.batch_type[1] == "chained":
            # (b n d) -> ((b n) d)
            latents = latents.view(-1, self.dim)
            latent_timestamp_emb = latent_timestamp_emb.view(-1, self.dim)
        elif self.batch_type[0] == "chained" and self.batch_type[1] == "stacked":
            # ((b n) d) -> (b n d)
            # assert all elements in latent_seqlen are the same
            assert latent_seqlen is not None
            if len(set(latent_seqlen.tolist())) != 1:
                raise NotImplementedError(
                    "Expected all latent sequences in the batch to have the same "
                    "length. Moving from chained to stacked is not supported yet."
                    f"Got {latent_seqlen}."
                )
            latents = latents.view(len(latent_seqlen), latent_seqlen[0], self.dim)
            latent_timestamp_emb = latent_timestamp_emb.view(
                len(latent_seqlen), latent_seqlen[0], self.dim
            )

        # process
        i = 4
        for self_attn, self_ff in self.proc_layers:
            latents = latents + self.dropout(
                self_attn(latents, latent_timestamp_emb, x_seqlen=latent_seqlen)
            )
            latents = latents + self.dropout(self_ff(latents))
            i += 1
        
        # print(f"Latents CV ({i}): {coef_variation(latents, 30)}")

        if output_queries is None:
            return latents

        output_timestamp_emb = self.rotary_emb(output_query_timestamps)

        if self.batch_type[1] == "stacked" and self.batch_type[2] == "chained":
            # (b n d) -> ((b n) d)
            latents = latents.view(-1, self.dim)
            latent_timestamp_emb = latent_timestamp_emb.view(-1, self.dim)
        elif self.batch_type[1] == "chained" and self.batch_type[2] == "stacked":
            # ((b n) d) -> (b n d)
            # assert all elements in output_query_seqlen are the same
            assert latent_seqlen is not None
            if len(set(latent_seqlen)) != 1:
                raise NotImplementedError(
                    "Expected all latent sequences in the batch to have the same "
                    "length. Moving from chained to stacked is not supported yet."
                )
            latents = latents.view(len(latent_seqlen), latent_seqlen[0], self.dim)
            latent_timestamp_emb = latent_timestamp_emb.view(
                len(latent_seqlen), latent_seqlen[0], self.dim
            )

        # breakpoint()
        # decode
        output_queries = output_queries + self.dec_atn(
            output_queries,
            latents,
            output_timestamp_emb,
            latent_timestamp_emb,
            context_mask=None,
            query_seqlen=output_query_seqlen,
            context_seqlen=latent_seqlen,
        )
        # print(f"Output Queries CV (2): {coef_variation(output_queries, 30)}")
        output_queries = output_queries + self.dec_ffn(output_queries)
        # print(f"Output Queries CV (3): {coef_variation(output_queries, 30)}")

        # breakpoint()

        return output_queries
